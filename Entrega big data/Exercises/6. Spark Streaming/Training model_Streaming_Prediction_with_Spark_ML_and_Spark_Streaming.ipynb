{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ba9a31f",
      "metadata": {
        "id": "9ba9a31f"
      },
      "source": [
        "# Streaming Prediction with Spark ML and Spark Streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80ea30cb",
      "metadata": {
        "id": "80ea30cb"
      },
      "source": [
        "In this notebook we are going to train a classification model to predict a patient's probability of suffering a heart attack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6318a507",
      "metadata": {
        "id": "6318a507"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4878544d",
      "metadata": {
        "id": "4878544d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cecab8",
      "metadata": {
        "id": "56cecab8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('UCI Heart disease').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe3c31c",
      "metadata": {
        "id": "afe3c31c",
        "outputId": "865fba3f-2698-4b4b-85ef-d48fbd1cdb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart = spark.read.csv('data/heart.csv', \n",
        "                       inferSchema = True, \n",
        "                       header = True)\n",
        "heart.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8216cc4",
      "metadata": {
        "id": "e8216cc4"
      },
      "outputs": [],
      "source": [
        "schema = StructType( \\\n",
        "                     [StructField(\"age\", LongType(),True), \\\n",
        "                      StructField(\"sex\", LongType(), True), \\\n",
        "                      StructField(\"cp\", LongType(), True), \\\n",
        "                      StructField('trestbps', LongType(), True), \\\n",
        "                      StructField(\"chol\", LongType(), True), \\\n",
        "                      StructField(\"fbs\", LongType(), True), \\\n",
        "                      StructField(\"restecg\", LongType(), True), \\\n",
        "                      StructField(\"thalach\", LongType(), True),\\\n",
        "                      StructField(\"exang\", LongType(), True), \\\n",
        "                      StructField(\"oldpeak\", DoubleType(), True), \\\n",
        "                      StructField(\"slope\", LongType(),True), \\\n",
        "                      StructField(\"ca\", LongType(), True), \\\n",
        "                      StructField(\"thal\", LongType(), True), \\\n",
        "                      StructField(\"target\", LongType(), True), \\\n",
        "                        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d8812f",
      "metadata": {
        "id": "28d8812f",
        "outputId": "ae0a4b8d-70da-4802-a1e1-3ded8245d950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: double (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.types import StructType,StructField,LongType, StringType,DoubleType,TimestampType\n",
        "\n",
        "df = heart.withColumnRenamed(\"target\",\"label\")\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2c3b4b",
      "metadata": {
        "id": "1b2c3b4b"
      },
      "outputs": [],
      "source": [
        "testDF, trainDF = df.randomSplit([0.3, 0.7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea2376e",
      "metadata": {
        "id": "9ea2376e"
      },
      "outputs": [],
      "source": [
        "# Create the logistic regression model\n",
        "lr = LogisticRegression(maxIter=10, regParam= 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4007600c",
      "metadata": {
        "id": "4007600c"
      },
      "outputs": [],
      "source": [
        "# We create a one hot encoder.\n",
        "ohe = OneHotEncoder(inputCols = ['sex', 'cp', 'fbs', 'restecg', 'slope', \n",
        "                                 'exang', 'ca', 'thal'], \n",
        "                    outputCols=['sex_ohe', 'cp_ohe', 'fbs_ohe', \n",
        "                                'restecg_ohe', 'slp_ohe', 'exng_ohe', \n",
        "                                'caa_ohe', 'thall_ohe'])\n",
        "\n",
        "# Input list for scaling\n",
        "inputs = ['age','trestbps','chol','thalach','oldpeak']\n",
        "\n",
        "# We scale our inputs\n",
        "assembler1 = VectorAssembler(inputCols=inputs, outputCol=\"features_scaled1\")\n",
        "scaler = MinMaxScaler(inputCol=\"features_scaled1\", outputCol=\"features_scaled\")\n",
        "\n",
        "# We create a second assembler for the encoded columns.\n",
        "assembler2 = VectorAssembler(inputCols=['sex_ohe', 'cp_ohe', \n",
        "                                        'fbs_ohe', 'restecg_ohe', \n",
        "                                        'slp_ohe', 'exng_ohe', 'caa_ohe', \n",
        "                                        'thall_ohe','features_scaled'], \n",
        "                             outputCol=\"features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247fdb95",
      "metadata": {
        "id": "247fdb95"
      },
      "outputs": [],
      "source": [
        "# Create stages list\n",
        "myStages = [assembler1, scaler, ohe, assembler2,lr]\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = Pipeline(stages= myStages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab63f90",
      "metadata": {
        "id": "8ab63f90",
        "outputId": "35dd54a8-2e7c-494f-e444-71e5943cd24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+----------+\n",
            "|label|         probability|prediction|\n",
            "+-----+--------------------+----------+\n",
            "|    1|[0.02547572141032...|       1.0|\n",
            "|    1|[0.00529737717862...|       1.0|\n",
            "|    1|[0.01433771555471...|       1.0|\n",
            "|    1|[0.03186502726837...|       1.0|\n",
            "|    0|[0.91655787910351...|       0.0|\n",
            "|    0|[0.76284874224638...|       0.0|\n",
            "|    1|[0.02615684728437...|       1.0|\n",
            "|    1|[0.00285662444432...|       1.0|\n",
            "|    1|[0.03955333515046...|       1.0|\n",
            "|    1|[0.03960488368718...|       1.0|\n",
            "|    0|[0.55115516202987...|       0.0|\n",
            "|    1|[0.00119850446011...|       1.0|\n",
            "|    1|[0.01842522915928...|       1.0|\n",
            "|    0|[0.70706060938886...|       0.0|\n",
            "|    1|[0.03740470373666...|       1.0|\n",
            "|    0|[0.94157151280181...|       0.0|\n",
            "|    0|[0.30476847727903...|       1.0|\n",
            "|    1|[0.19848850346177...|       1.0|\n",
            "|    1|[0.04391393058917...|       1.0|\n",
            "|    1|[0.01665766697008...|       1.0|\n",
            "+-----+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We fit the model using the training data.\n",
        "pModel = pipeline.fit(trainDF)\n",
        "\n",
        "# We transform the data.\n",
        "trainingPred = pModel.transform(trainDF)\n",
        "\n",
        "# # We select the actual label, probability and predictions\n",
        "trainingPred.select('label','probability','prediction').show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pModel.save(\"/pipelines\")"
      ],
      "metadata": {
        "id": "SwwqbzZr37Iw"
      },
      "id": "SwwqbzZr37Iw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3391605d",
      "metadata": {
        "id": "3391605d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}